# bsp_safety_detection

Real-Time Safety Gear Detection SystemIn high-risk industrial environments like construction sites and manufacturing plants, ensuring workers wear Personal Protective Equipment (PPE) such as helmets and safety vests is crucial for preventing injuries. Traditional manual monitoring is often inefficient, prone to human error, and difficult to scale. This project presents an automated, real-time safety gear detection system designed to overcome these challenges.Leveraging the power of computer vision and deep learning, the system uses a fine-tuned YOLOv8 model to analyze video feeds from sources like webcams, CCTV, or pre-recorded files. It accurately identifies workers in the frame and verifies if they are wearing the required safety helmets and vests.When a violation is detected—a person without a helmet—the system instantly triggers an audible alarm to alert supervisors for immediate intervention. To aid in safety audits and incident reviews, the application also automatically captures and saves an image of the non-compliant event.The solution features a user-friendly desktop application built with Python and Tkinter, making it accessible to non-technical personnel. During a successful pilot implementation at Sinter Plant-3, a steel manufacturing facility, the system demonstrated its real-world viability by achieving approximately 80% detection accuracy and integrating seamlessly with the plant's existing electrical alarm infrastructure. This project provides a scalable and effective blueprint for enhancing workplace safety culture and ensuring consistent enforcement of safety protocols through technology.Key FeaturesReal-Time Detection: Analyzes live video feeds from webcams or CCTV cameras.Multi-Source Input: Supports detection in pre-recorded videos and static images.Automated Alarms: Triggers an audible alarm when a person is detected without a safety helmet.Auto-Capture Violations: Automatically saves an image of the frame when non-compliance is detected (with a 15-second cooldown).User-Friendly Interface: A simple and intuitive desktop application built with Tkinter.Adjustable Confidence: Allows users to set the detection confidence threshold.Technology StackPython: Core programming language.YOLOv8: State-of-the-art object detection model from Ultralytics.OpenCV: For video and image processing.PyTorch: The backend framework for the YOLOv8 model.Tkinter: For the graphical user interface (GUI).NumPy: For efficient numerical operations.Roboflow: For dataset management and preprocessing.Google Colab: For training the deep learning model on a GPU.MethodologyThe system was developed following these key steps:Data Preparation: The project utilizes the "construction-safety-gsevb" dataset from Roboflow. The data was preprocessed and augmented to improve model robustness.Model Training: The YOLOv8-nano model, pre-trained on the COCO dataset, was fine-tuned on our custom safety gear dataset for 50 epochs using Google Colab.System Development: A desktop application was built using Python and Tkinter to provide an interface for the model. The detection logic checks if the number of detected persons exceeds the number of helmets and triggers an alarm accordingly.Pilot Deployment: The system was successfully piloted at Sinter Plant-3, a steel manufacturing facility, and integrated with the plant's electrical alarm system.Setup and InstallationFollow these steps to set up the project on your local machine.1. Clone the repository:git clone [https://github.com/princeg06-byte/bsp_safety_detection.git](https://github.com/princeg06-byte/bsp_safety_detection.git)
cd bsp_safety_detection
2. Create a virtual environment and activate it:# For Windows
python -m venv venv
venv\Scripts\activate

# For macOS/Linux
python3 -m venv venv
source venv/bin/activate
3. Install the required dependencies:pip install -r requirements.txt
4. Download the trained model:You need the trained model weights. Download the best.pt file from your training session and place it in the root directory of this project.UsageTo run the application, execute the following command in your terminal:python main_app.py
The application will start, prompting you to select a detection mode (Live Webcam, Image, or Video).If you select "Live Webcam," the feed will open in a new window.Detection results and logs will be displayed in the main application window.Screenshots(You can add screenshots of your application here)Fig 1: Main Application InterfaceFig 2: Real-time detection with bounding boxes.ContributorsPrince (IIT Bhilai)
